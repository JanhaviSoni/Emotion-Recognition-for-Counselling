{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Fine Grained Emotion Recognition for Counselling/dreaddit-train.csv')\n",
    "test = pd.read_csv('../Fine Grained Emotion Recognition for Counselling/dreaddit-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = train['text'].values\n",
    "text_test = test['text'].values\n",
    "y_train = train['label'].values\n",
    "y_test = test['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "\n",
    "tagger=PerceptronTagger()\n",
    "wordnet = WordNetLemmatizer()\n",
    "corpus_train = []\n",
    "corpus_test =[]\n",
    "tagged = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    review = re.sub('^a-zA-Z^',' ',train['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [wordnet.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    tagged.append(tagger.tag(review))\n",
    "    review = ' '.join(review)\n",
    "    corpus_train.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey r/assistance, sure right place post this.. go =) i'm currently student intern sandia national lab working survey help improve marketing outreach effort many school recruit around country. we're looking current undergrad/grad stem student stem student know stem students, would greatly appreciate help take pas along short survey. thank you, everyone help take survey entered drawing chance win one three $50 amazon gcs. \n",
      " \n",
      " mom hit newspaper shocked would this, know like play hitting, smacking, striking, hitting violence sort person. send vibe asking universe? yesterday decided take friend go help another \"friend\" move new place. driving friend moving strike shoulder. address immediately 4th time told things, friend driving nearly get collision another car think high marijuana friend moving backseat like \"you understand trying get attention\" know thing 5 year old get people attention smacking them, guy 60's.\n"
     ]
    }
   ],
   "source": [
    "print(corpus_train[1],'\\n','\\n',corpus_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    review = re.sub('^a-zA-Z^',' ',test['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [wordnet.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    tagged.append(tagger.tag(review))\n",
    "    review = ' '.join(review)\n",
    "    corpus_test.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X_train = cv.fit_transform(corpus_train).toarray()\n",
    "X_test = cv.transform(corpus_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parts of speech tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('said', 'VBD') \n",
      " ('felt', 'JJ') \n",
      " ('way', 'NN') \n",
      " ('before,', 'NN') \n",
      " ('suggeted', 'VBD')\n"
     ]
    }
   ],
   "source": [
    "print(tagged[0][0],'\\n',tagged[0][1],'\\n',tagged[0][2],'\\n',tagged[0][3],'\\n',tagged[0][4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using Word2Vec\n",
    "# from gensim.models import Word2Vec\n",
    "# sentences_train = []\n",
    "# sentences_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cleaning data for Word2Vec in training dataset\n",
    "# for i in range(len(train)):\n",
    "#     review = re.sub('^a-zA-Z^',' ',train['text'][i])\n",
    "#     review = review.lower()\n",
    "#     review = review.split()\n",
    "    \n",
    "#     review = [word for word in review if word not in set(stopwords.words('english'))]\n",
    "#     sentences_train.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cleaning data for Word2Vec in testing dataset\n",
    "# for i in range(len(test)):\n",
    "#     review = re.sub('^a-zA-Z^',' ',test['text'][i])\n",
    "#     review = review.lower()\n",
    "#     review = review.split()\n",
    "    \n",
    "#     review = [word for word in review if word not in set(stopwords.words('english'))]\n",
    "#     sentences_test.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training Word2Vec\n",
    "# train_model = Word2Vec(sentences_train, min_count=1)# if word is present less than 1 skip that word\n",
    "# #test_model = Word2Vec(sentences_test, min_count=1)# if word is present less than 1 skip that word\n",
    "# train_model.save(\"word2vec_train.model\")\n",
    "# #test_model.save(\"word2vec_test.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_train = train_model.build_vocab(sentences_train)\n",
    "# words_test = test_model.build_vocab(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training word2vec\n",
    "# train_model.train(sentences_train,total_examples=train_model.corpus_count,epochs=1001)# corpus_count =2838\n",
    "# #test_model.train(sentences_test,total_examples=test_model.corpus_count,epochs=1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import KeyedVectors\n",
    "\n",
    "# # Store just the words + their trained embeddings.\n",
    "# word_vectors_train = train_model.wv\n",
    "# word_vectors_train.save(\"word2vec.wordvectors\")\n",
    "# word_vectors_test = train_model.wv\n",
    "# # word_vectors_test.save(\"word2vec.wordvectors\")\n",
    "# # Load back with memory-mapping = read-only, shared across processes.\n",
    "# wv = KeyedVectors.load(\"word2vec_train.wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Logistic Regression Model on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state =0)\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training K-NN Model on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SVM Model on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf' , random_state=0)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Naive Bayes Model on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "naive = GaussianNB()\n",
    "naive.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Decision Tree Model on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(criterion = 'entropy', random_state =0)\n",
    "dtc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Random Forest Model on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100 , criterion='entropy', random_state=0)\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training XGBoost on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:01:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr.predict(X_test)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_classifier = classifier.predict(X_test)\n",
    "y_pred_naive = naive.predict(X_test)\n",
    "y_pred_dtc = dtc.predict(X_test)\n",
    "y_pred_rfc = rfc.predict(X_test)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "# np.concatenate((y_test.reshape(len(y_test),1),y_pred.reshape(len(y_pred),1)),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : \n",
      " [[236 110]\n",
      " [ 92 277]]\n",
      "K-NN : \n",
      " [[235 111]\n",
      " [200 169]]\n",
      "SVM :  [[234 112]\n",
      " [ 95 274]]\n",
      "Naive Bayes : \n",
      " [[152 194]\n",
      " [ 97 272]]\n",
      "Decision Tree Classifier : \n",
      " [[174 172]\n",
      " [128 241]]\n",
      "Random Forest Classifier : \n",
      " [[188 158]\n",
      " [ 59 310]]\n",
      "\n",
      "\n",
      "Logistic Regression Classifier : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70       346\n",
      "           1       0.72      0.75      0.73       369\n",
      "\n",
      "    accuracy                           0.72       715\n",
      "   macro avg       0.72      0.72      0.72       715\n",
      "weighted avg       0.72      0.72      0.72       715\n",
      "\n",
      "K-Nearest Classifier : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.68      0.60       346\n",
      "           1       0.60      0.46      0.52       369\n",
      "\n",
      "    accuracy                           0.57       715\n",
      "   macro avg       0.57      0.57      0.56       715\n",
      "weighted avg       0.57      0.57      0.56       715\n",
      "\n",
      "SVM Classifier : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.69       346\n",
      "           1       0.71      0.74      0.73       369\n",
      "\n",
      "    accuracy                           0.71       715\n",
      "   macro avg       0.71      0.71      0.71       715\n",
      "weighted avg       0.71      0.71      0.71       715\n",
      "\n",
      "Naive Bayes Classifier : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.44      0.51       346\n",
      "           1       0.58      0.74      0.65       369\n",
      "\n",
      "    accuracy                           0.59       715\n",
      "   macro avg       0.60      0.59      0.58       715\n",
      "weighted avg       0.60      0.59      0.58       715\n",
      "\n",
      "Decision Tress Classifier : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.50      0.54       346\n",
      "           1       0.58      0.65      0.62       369\n",
      "\n",
      "    accuracy                           0.58       715\n",
      "   macro avg       0.58      0.58      0.58       715\n",
      "weighted avg       0.58      0.58      0.58       715\n",
      "\n",
      "Random Forest Classifier : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.54      0.63       346\n",
      "           1       0.66      0.84      0.74       369\n",
      "\n",
      "    accuracy                           0.70       715\n",
      "   macro avg       0.71      0.69      0.69       715\n",
      "weighted avg       0.71      0.70      0.69       715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "cm_lr = confusion_matrix(y_test,y_pred_lr)\n",
    "print('Logistic Regression : \\n',cm_lr)\n",
    "cm_knn = confusion_matrix(y_test,y_pred_knn)\n",
    "print('K-NN : \\n',cm_knn)\n",
    "cm_classifier = confusion_matrix(y_test,y_pred_classifier)\n",
    "print('SVM : ',cm_classifier)\n",
    "cm_naive = confusion_matrix(y_test,y_pred_naive)\n",
    "print('Naive Bayes : \\n',cm_naive)\n",
    "cm_dtc = confusion_matrix(y_test,y_pred_dtc)\n",
    "print('Decision Tree Classifier : \\n',cm_dtc)\n",
    "cm_rfc = confusion_matrix(y_test,y_pred_rfc)\n",
    "print('Random Forest Classifier : \\n', cm_rfc)\n",
    "\n",
    "print('\\n')\n",
    "print('Logistic Regression Classifier : \\n')\n",
    "print(classification_report(y_test,y_pred_lr))\n",
    "print('K-Nearest Classifier : \\n')\n",
    "print(classification_report(y_test,y_pred_knn))\n",
    "print('SVM Classifier : \\n')\n",
    "print(classification_report(y_test,y_pred_classifier))\n",
    "print('Naive Bayes Classifier : \\n')\n",
    "print(classification_report(y_test,y_pred_naive))\n",
    "print('Decision Tress Classifier : \\n')\n",
    "print(classification_report(y_test,y_pred_dtc))\n",
    "print('Random Forest Classifier : \\n')\n",
    "print(classification_report(y_test,y_pred_rfc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model\n",
    "param_grid = [    \n",
    "    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 300 ,500, 1000]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(lr, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = clf.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, grid_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf', 'linear']} \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "\n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "# print(grid.best_estimator_)\n",
    "\n",
    "grid_predictions = grid.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, grid_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Stemming for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "corpus_train_stem = []\n",
    "corpus_test_stem = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    review = re.sub('^a-zA-Z^',' ',train['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [stemmer.stem(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    tagged.append(tagger.tag(review))\n",
    "    review = ' '.join(review)\n",
    "    corpus_train_stem.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    review = re.sub('^a-zA-Z^',' ',test['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [stemmer.stem(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    tagged.append(tagger.tag(review))\n",
    "    review = ' '.join(review)\n",
    "    corpus_test_stem.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X_train_stem = cv.fit_transform(corpus_train_stem).toarray()\n",
    "X_test_stem = cv.transform(corpus_test_stem).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lr = LogisticRegression(random_state =0)\n",
    "lr.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "knn.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier = SVC(kernel = 'rbf' , random_state=0)\n",
    "classifier.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "naive = GaussianNB()\n",
    "naive.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dtc = DecisionTreeClassifier(criterion = 'entropy', random_state =0)\n",
    "dtc.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100 , criterion='entropy', random_state=0)\n",
    "rfc.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr.predict(X_test_stem)\n",
    "y_pred_knn = knn.predict(X_test_stem)\n",
    "y_pred_classifier = classifier.predict(X_test_stem)\n",
    "y_pred_naive = naive.predict(X_test_stem)\n",
    "y_pred_dtc = dtc.predict(X_test_stem)\n",
    "y_pred_rfc = rfc.predict(X_test_stem)\n",
    "y_pred_xgb = xgb.predict(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : \n",
      " [[241 105]\n",
      " [ 85 284]]\n",
      "K-NN : \n",
      " [[231 115]\n",
      " [197 172]]\n",
      "SVM :  [[246 100]\n",
      " [ 97 272]]\n",
      "Naive Bayes : \n",
      " [[123 223]\n",
      " [ 97 272]]\n",
      "Decision Tree Classifier : \n",
      " [[185 161]\n",
      " [130 239]]\n",
      "Random Forest Classifier : \n",
      " [[195 151]\n",
      " [ 60 309]]\n",
      "XGBoost Classifier : \n",
      " [[222 124]\n",
      " [ 94 275]]\n",
      "\n",
      "\n",
      "Logistic Regression Classifier : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72       346\n",
      "           1       0.73      0.77      0.75       369\n",
      "\n",
      "    accuracy                           0.73       715\n",
      "   macro avg       0.73      0.73      0.73       715\n",
      "weighted avg       0.73      0.73      0.73       715\n",
      "\n",
      "K-Nearest Classifier : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.60       346\n",
      "           1       0.60      0.47      0.52       369\n",
      "\n",
      "    accuracy                           0.56       715\n",
      "   macro avg       0.57      0.57      0.56       715\n",
      "weighted avg       0.57      0.56      0.56       715\n",
      "\n",
      "SVM Classifier : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.71       346\n",
      "           1       0.73      0.74      0.73       369\n",
      "\n",
      "    accuracy                           0.72       715\n",
      "   macro avg       0.72      0.72      0.72       715\n",
      "weighted avg       0.72      0.72      0.72       715\n",
      "\n",
      "Naive Bayes Classifier : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.36      0.43       346\n",
      "           1       0.55      0.74      0.63       369\n",
      "\n",
      "    accuracy                           0.55       715\n",
      "   macro avg       0.55      0.55      0.53       715\n",
      "weighted avg       0.55      0.55      0.54       715\n",
      "\n",
      "Decision Tress Classifier : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.53      0.56       346\n",
      "           1       0.60      0.65      0.62       369\n",
      "\n",
      "    accuracy                           0.59       715\n",
      "   macro avg       0.59      0.59      0.59       715\n",
      "weighted avg       0.59      0.59      0.59       715\n",
      "\n",
      "Random Forest Classifier : \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.56      0.65       346\n",
      "           1       0.67      0.84      0.75       369\n",
      "\n",
      "    accuracy                           0.70       715\n",
      "   macro avg       0.72      0.70      0.70       715\n",
      "weighted avg       0.72      0.70      0.70       715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cm_lr = confusion_matrix(y_test,y_pred_lr)\n",
    "print('Logistic Regression : \\n',cm_lr)\n",
    "cm_knn = confusion_matrix(y_test,y_pred_knn)\n",
    "print('K-NN : \\n',cm_knn)\n",
    "cm_classifier = confusion_matrix(y_test,y_pred_classifier)\n",
    "print('SVM : ',cm_classifier)\n",
    "cm_naive = confusion_matrix(y_test,y_pred_naive)\n",
    "print('Naive Bayes : \\n',cm_naive)\n",
    "cm_dtc = confusion_matrix(y_test,y_pred_dtc)\n",
    "print('Decision Tree Classifier : \\n',cm_dtc)\n",
    "cm_rfc = confusion_matrix(y_test,y_pred_rfc)\n",
    "print('Random Forest Classifier : \\n', cm_rfc)\n",
    "cm_xgb = confusion_matrix(y_test,y_pred_xgb)\n",
    "print('XGBoost Classifier : \\n', cm_xgb)\n",
    "\n",
    "print('\\n')\n",
    "print('Logistic Regression Classifier : \\n')\n",
    "print(classification_report(y_test,y_pred_lr))\n",
    "print('K-Nearest Classifier : \\n')\n",
    "print(classification_report(y_test,y_pred_knn))\n",
    "print('SVM Classifier : \\n')\n",
    "print(classification_report(y_test,y_pred_classifier))\n",
    "print('Naive Bayes Classifier : \\n')\n",
    "print(classification_report(y_test,y_pred_naive))\n",
    "print('Decision Tress Classifier : \\n')\n",
    "print(classification_report(y_test,y_pred_dtc))\n",
    "print('Random Forest Classifier : \\n')\n",
    "print(classification_report(y_test,y_pred_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning the Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [2, 5, 10, 14], 'min_samples_leaf': [1, 2, 4, 6, 8], 'criterion': ['entropy', 'gini']}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 1000,10)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10,14]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,6,8]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              'criterion':['entropy','gini']}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 50.7min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 103.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['entropy', 'gini'],\n",
       "                                        'max_depth': [10, 120, 230, 340, 450,\n",
       "                                                      560, 670, 780, 890,\n",
       "                                                      1000],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
       "                                        'min_samples_split': [2, 5, 10, 14],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=100, verbose=2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier()\n",
    "rf_randomcv=RandomizedSearchCV(estimator=rf,param_distributions=random_grid,n_iter=100,cv=3,verbose=2,\n",
    "                               random_state=100,n_jobs=-1)\n",
    "### fit the randomized model\n",
    "rf_randomcv.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1400,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 1000,\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_randomcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['entropy', 'gini'],\n",
       "                                        'max_depth': [10, 120, 230, 340, 450,\n",
       "                                                      560, 670, 780, 890,\n",
       "                                                      1000],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
       "                                        'min_samples_split': [2, 5, 10, 14],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=100, verbose=2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_randomcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_grid=rf_randomcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1400,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 1000,\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_randomcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_Model = RandomForestClassifier(n_estimators= 1400,min_samples_split = 2,min_samples_leaf = 2,max_features = 'sqrt',max_depth = 1000,\n",
    " criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=1000, max_features='sqrt',\n",
       "                       min_samples_leaf=2, n_estimators=1400)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_Model.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[211 135]\n",
      " [ 68 301]]\n",
      "Accuracy Score 0.7160839160839161\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.61      0.68       346\n",
      "           1       0.69      0.82      0.75       369\n",
      "\n",
      "    accuracy                           0.72       715\n",
      "   macro avg       0.72      0.71      0.71       715\n",
      "weighted avg       0.72      0.72      0.71       715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_rand=rf_Model.predict(X_test_stem)\n",
    "print(confusion_matrix(y_test,y_pred_rand))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred_rand)))\n",
    "print(\"Classification report: {}\".format(classification_report(y_test,y_pred_rand)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {\n",
    "        'C' : [0.25, 0.5, 0.75],\n",
    "        'kernel' : ['rbf'], 'gamma' : [0.1,0.01,0.001]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_Model = SVC(C =0.25,kernel='rbf',gamma =0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.25, gamma=0.01)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_Model.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm_Model.predict(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[236 110]\n",
      " [103 266]]\n",
      "Accuracy Score 0.7020979020979021\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69       346\n",
      "           1       0.71      0.72      0.71       369\n",
      "\n",
      "    accuracy                           0.70       715\n",
      "   macro avg       0.70      0.70      0.70       715\n",
      "weighted avg       0.70      0.70      0.70       715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_svm))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred_svm)))\n",
    "print(\"Classification report: {}\".format(classification_report(y_test,y_pred_svm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_Model2 = SVC(C =0.5,kernel='rbf',gamma =0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.5, gamma=0.01)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_Model2.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm2 = svm_Model2.predict(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[247  99]\n",
      " [104 265]]\n",
      "Accuracy Score 0.7160839160839161\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.71       346\n",
      "           1       0.73      0.72      0.72       369\n",
      "\n",
      "    accuracy                           0.72       715\n",
      "   macro avg       0.72      0.72      0.72       715\n",
      "weighted avg       0.72      0.72      0.72       715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_svm2))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred_svm2)))\n",
    "print(\"Classification report: {}\".format(classification_report(y_test,y_pred_svm2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_Model4 = SVC(C =0.5,kernel='rbf',gamma =0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.5, gamma=0.02)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_Model4.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm4 = svm_Model4.predict(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[239 107]\n",
      " [100 269]]\n",
      "Accuracy Score 0.7104895104895105\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       346\n",
      "           1       0.72      0.73      0.72       369\n",
      "\n",
      "    accuracy                           0.71       715\n",
      "   macro avg       0.71      0.71      0.71       715\n",
      "weighted avg       0.71      0.71      0.71       715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_svm4))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred_svm4)))\n",
    "print(\"Classification report: {}\".format(classification_report(y_test,y_pred_svm4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_Model3 = SVC(C =0.75,kernel='rbf',gamma =0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.75, gamma=0.01)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_Model3.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm3 = svm_Model3.predict(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[250  96]\n",
      " [100 269]]\n",
      "Accuracy Score 0.7258741258741259\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.72       346\n",
      "           1       0.74      0.73      0.73       369\n",
      "\n",
      "    accuracy                           0.73       715\n",
      "   macro avg       0.73      0.73      0.73       715\n",
      "weighted avg       0.73      0.73      0.73       715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_svm3))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred_svm3)))\n",
    "print(\"Classification report: {}\".format(classification_report(y_test,y_pred_svm3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_Model6 = SVC(C =0.75,kernel='rbf',gamma =0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.75, gamma=0.02)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_Model6.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm6 = svm_Model6.predict(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[245 101]\n",
      " [ 95 274]]\n",
      "Accuracy Score 0.7258741258741259\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.71       346\n",
      "           1       0.73      0.74      0.74       369\n",
      "\n",
      "    accuracy                           0.73       715\n",
      "   macro avg       0.73      0.73      0.73       715\n",
      "weighted avg       0.73      0.73      0.73       715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_svm6))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred_svm6)))\n",
    "print(\"Classification report: {}\".format(classification_report(y_test,y_pred_svm6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_Model7 = SVC(C =0.75,kernel='rbf',gamma =0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.75, gamma=0.03)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_Model7.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm7 = svm_Model7.predict(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[235 111]\n",
      " [ 90 279]]\n",
      "Accuracy Score 0.7188811188811188\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70       346\n",
      "           1       0.72      0.76      0.74       369\n",
      "\n",
      "    accuracy                           0.72       715\n",
      "   macro avg       0.72      0.72      0.72       715\n",
      "weighted avg       0.72      0.72      0.72       715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_svm7))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred_svm7)))\n",
    "print(\"Classification report: {}\".format(classification_report(y_test,y_pred_svm7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_Model8 = SVC(C =1,kernel='rbf',gamma =0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, gamma=0.01)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_Model8.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm8 = svm_Model8.predict(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[248  98]\n",
      " [ 97 272]]\n",
      "Accuracy Score 0.7272727272727273\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72       346\n",
      "           1       0.74      0.74      0.74       369\n",
      "\n",
      "    accuracy                           0.73       715\n",
      "   macro avg       0.73      0.73      0.73       715\n",
      "weighted avg       0.73      0.73      0.73       715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_svm8))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred_svm8)))\n",
    "print(\"Classification report: {}\".format(classification_report(y_test,y_pred_svm8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_Model9 = SVC(C =1,kernel='rbf',gamma =0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, gamma=0.02)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_Model9.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm9 = svm_Model9.predict(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[246 100]\n",
      " [ 95 274]]\n",
      "Accuracy Score 0.7272727272727273\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.72       346\n",
      "           1       0.73      0.74      0.74       369\n",
      "\n",
      "    accuracy                           0.73       715\n",
      "   macro avg       0.73      0.73      0.73       715\n",
      "weighted avg       0.73      0.73      0.73       715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_svm9))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred_svm9)))\n",
    "print(\"Classification report: {}\".format(classification_report(y_test,y_pred_svm9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_nb = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_Model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbModel_grid = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(), n_jobs=-1,\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.848035...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbModel_grid.fit(X_train_stem, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_best_accuracy = nbModel_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_best_parameters = nbModel_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy - : 0.757\n",
      "Test Accuracy - : 0.702\n"
     ]
    }
   ],
   "source": [
    "print (f'Train Accuracy - : {nbModel_grid.score(X_train_stem,y_train):.3f}')\n",
    "print (f'Test Accuracy - : {nbModel_grid.score(X_test_stem,y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[206 140]\n",
      " [ 73 296]]\n",
      "Accuracy Score 0.7020979020979021\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.60      0.66       346\n",
      "           1       0.68      0.80      0.74       369\n",
      "\n",
      "    accuracy                           0.70       715\n",
      "   macro avg       0.71      0.70      0.70       715\n",
      "weighted avg       0.71      0.70      0.70       715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_nb = nbModel_grid.predict(X_test_stem)\n",
    "print(confusion_matrix(y_test,y_pred_nb))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred_nb)))\n",
    "print(\"Classification report: {}\".format(classification_report(y_test,y_pred_nb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = [\n",
    "    {\n",
    "     'penalty' : ['l1', 'l2'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['liblinear']},\n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf_lr = GridSearchCV(estimator=LogisticRegression(), param_grid = param_grid_lr, cv = 5, verbose=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "# Fit on data\n",
    "\n",
    "best_clf_lr = clf_lr.fit(X_train_stem, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_best_accuracy = clf_lr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_best_parameters = clf_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy - : 0.874\n",
      "Test Accuracy - : 0.740\n"
     ]
    }
   ],
   "source": [
    "print (f'Train Accuracy - : {clf_lr.score(X_train_stem,y_train):.3f}')\n",
    "print (f'Test Accuracy - : {clf_lr.score(X_test_stem,y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[243 103]\n",
      " [ 83 286]]\n",
      "Accuracy Score 0.7398601398601399\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.72       346\n",
      "           1       0.74      0.78      0.75       369\n",
      "\n",
      "    accuracy                           0.74       715\n",
      "   macro avg       0.74      0.74      0.74       715\n",
      "weighted avg       0.74      0.74      0.74       715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr = clf_lr.predict(X_test_stem)\n",
    "print(confusion_matrix(y_test,y_pred_lr))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred_lr)))\n",
    "print(\"Classification report: {}\".format(classification_report(y_test,y_pred_lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
