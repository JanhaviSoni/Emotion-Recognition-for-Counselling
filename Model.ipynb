{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Fine Grained Emotion Recognition for Counselling/dreaddit-train.csv')\n",
    "test = pd.read_csv('../Fine Grained Emotion Recognition for Counselling/dreaddit-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = train['text'].values\n",
    "text_test = test['text'].values\n",
    "y_train = train['label'].values\n",
    "y_test = test['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "\n",
    "tagger=PerceptronTagger()\n",
    "wordnet = WordNetLemmatizer()\n",
    "corpus_train = []\n",
    "corpus_test =[]\n",
    "tagged = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    review = re.sub('^a-zA-Z^',' ',train['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [wordnet.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    tagged.append(tagger.tag(review))\n",
    "    review = ' '.join(review)\n",
    "    corpus_train.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey r/assistance, sure right place post this.. go =) i'm currently student intern sandia national lab working survey help improve marketing outreach effort many school recruit around country. we're looking current undergrad/grad stem student stem student know stem students, would greatly appreciate help take pas along short survey. thank you, everyone help take survey entered drawing chance win one three $50 amazon gcs. \n",
      " \n",
      " mom hit newspaper shocked would this, know like play hitting, smacking, striking, hitting violence sort person. send vibe asking universe? yesterday decided take friend go help another \"friend\" move new place. driving friend moving strike shoulder. address immediately 4th time told things, friend driving nearly get collision another car think high marijuana friend moving backseat like \"you understand trying get attention\" know thing 5 year old get people attention smacking them, guy 60's.\n"
     ]
    }
   ],
   "source": [
    "print(corpus_train[1],'\\n','\\n',corpus_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    review = re.sub('^a-zA-Z^',' ',test['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [wordnet.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    tagged.append(tagger.tag(review))\n",
    "    review = ' '.join(review)\n",
    "    corpus_test.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X_train = cv.fit_transform(corpus_train).toarray()\n",
    "X_test = cv.transform(corpus_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parts of speech tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('said', 'VBD') \n",
      " ('felt', 'JJ') \n",
      " ('way', 'NN') \n",
      " ('before,', 'NN') \n",
      " ('suggeted', 'VBD')\n"
     ]
    }
   ],
   "source": [
    "print(tagged[0][0],'\\n',tagged[0][1],'\\n',tagged[0][2],'\\n',tagged[0][3],'\\n',tagged[0][4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using Word2Vec\n",
    "# from gensim.models import Word2Vec\n",
    "# sentences_train = []\n",
    "# sentences_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cleaning data for Word2Vec in training dataset\n",
    "# for i in range(len(train)):\n",
    "#     review = re.sub('^a-zA-Z^',' ',train['text'][i])\n",
    "#     review = review.lower()\n",
    "#     review = review.split()\n",
    "    \n",
    "#     review = [word for word in review if word not in set(stopwords.words('english'))]\n",
    "#     sentences_train.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cleaning data for Word2Vec in testing dataset\n",
    "# for i in range(len(test)):\n",
    "#     review = re.sub('^a-zA-Z^',' ',test['text'][i])\n",
    "#     review = review.lower()\n",
    "#     review = review.split()\n",
    "    \n",
    "#     review = [word for word in review if word not in set(stopwords.words('english'))]\n",
    "#     sentences_test.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training Word2Vec\n",
    "# train_model = Word2Vec(sentences_train, min_count=1)# if word is present less than 1 skip that word\n",
    "# #test_model = Word2Vec(sentences_test, min_count=1)# if word is present less than 1 skip that word\n",
    "# train_model.save(\"word2vec_train.model\")\n",
    "# #test_model.save(\"word2vec_test.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_train = train_model.build_vocab(sentences_train)\n",
    "# words_test = test_model.build_vocab(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training word2vec\n",
    "# train_model.train(sentences_train,total_examples=train_model.corpus_count,epochs=1001)# corpus_count =2838\n",
    "# #test_model.train(sentences_test,total_examples=test_model.corpus_count,epochs=1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import KeyedVectors\n",
    "\n",
    "# # Store just the words + their trained embeddings.\n",
    "# word_vectors_train = train_model.wv\n",
    "# word_vectors_train.save(\"word2vec.wordvectors\")\n",
    "# word_vectors_test = train_model.wv\n",
    "# # word_vectors_test.save(\"word2vec.wordvectors\")\n",
    "# # Load back with memory-mapping = read-only, shared across processes.\n",
    "# wv = KeyedVectors.load(\"word2vec_train.wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Logistic Regression Model on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state =0)\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training K-NN Model on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SVM Model on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf' , random_state=0)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Naive Bayes Model on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "naive = GaussianNB()\n",
    "naive.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Decision Tree Model on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(criterion = 'entropy', random_state =0)\n",
    "dtc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Random Forest Model on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100 , criterion='entropy', random_state=0)\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr.predict(X_test)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_classifier = classifier.predict(X_test)\n",
    "y_pred_naive = naive.predict(X_test)\n",
    "y_pred_dtc = dtc.predict(X_test)\n",
    "y_pred_rfc = rfc.predict(X_test)\n",
    "\n",
    "# np.concatenate((y_test.reshape(len(y_test),1),y_pred.reshape(len(y_pred),1)),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : \n",
      " [[236 110]\n",
      " [ 92 277]]\n",
      "K-NN : \n",
      " [[235 111]\n",
      " [200 169]]\n",
      "SVM :  [[234 112]\n",
      " [ 95 274]]\n",
      "Naive Bayes : \n",
      " [[152 194]\n",
      " [ 97 272]]\n",
      "Decision Tree Classifier : \n",
      " [[174 172]\n",
      " [128 241]]\n",
      "Random Forest Classifier : \n",
      " [[188 158]\n",
      " [ 59 310]]\n",
      "Accuracy of Logistic Regression Classifier is : 0.7174825174825175 \n",
      "\n",
      "Accuracy of K_NN Classifier is : 0.5650349650349651 \n",
      "\n",
      "Accuracy of SVM Classifier is : 0.7104895104895105 \n",
      "\n",
      "Accuracy of Naive Bayes Classifier is : 0.593006993006993 \n",
      "\n",
      "Accuracy of Decision Tree Classifier is : 0.5804195804195804 \n",
      "\n",
      "Accuracy of Random Forest Classifier is : 0.6965034965034965 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm_lr = confusion_matrix(y_test,y_pred_lr)\n",
    "print('Logistic Regression : \\n',cm_lr)\n",
    "cm_knn = confusion_matrix(y_test,y_pred_knn)\n",
    "print('K-NN : \\n',cm_knn)\n",
    "cm_classifier = confusion_matrix(y_test,y_pred_classifier)\n",
    "print('SVM : ',cm_classifier)\n",
    "cm_naive = confusion_matrix(y_test,y_pred_naive)\n",
    "print('Naive Bayes : \\n',cm_naive)\n",
    "cm_dtc = confusion_matrix(y_test,y_pred_dtc)\n",
    "print('Decision Tree Classifier : \\n',cm_dtc)\n",
    "cm_rfc = confusion_matrix(y_test,y_pred_rfc)\n",
    "print('Random Forest Classifier : \\n', cm_rfc)\n",
    "print('Accuracy of Logistic Regression Classifier is :', accuracy_score(y_test,y_pred_lr),'\\n')\n",
    "print('Accuracy of K_NN Classifier is :', accuracy_score(y_test,y_pred_knn),'\\n')\n",
    "print('Accuracy of SVM Classifier is :' ,accuracy_score(y_test,y_pred_classifier),'\\n')\n",
    "print('Accuracy of Naive Bayes Classifier is :', accuracy_score(y_test,y_pred_naive),'\\n')\n",
    "print('Accuracy of Decision Tree Classifier is :',accuracy_score(y_test,y_pred_dtc),'\\n')\n",
    "print('Accuracy of Random Forest Classifier is :' ,accuracy_score(y_test,y_pred_rfc),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Stemming for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "corpus_train_stem = []\n",
    "corpus_test_stem = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    review = re.sub('^a-zA-Z^',' ',train['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [stemmer.stem(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    tagged.append(tagger.tag(review))\n",
    "    review = ' '.join(review)\n",
    "    corpus_train_stem.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    review = re.sub('^a-zA-Z^',' ',test['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [stemmer.stem(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    tagged.append(tagger.tag(review))\n",
    "    review = ' '.join(review)\n",
    "    corpus_test_stem.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X_train_stem = cv.fit_transform(corpus_train_stem).toarray()\n",
    "X_test_stem = cv.transform(corpus_test_stem).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state =0)\n",
    "lr.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "knn.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf' , random_state=0)\n",
    "classifier.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "naive = GaussianNB()\n",
    "naive.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(criterion = 'entropy', random_state =0)\n",
    "dtc.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100 , criterion='entropy', random_state=0)\n",
    "rfc.fit(X_train_stem,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr.predict(X_test_stem)\n",
    "y_pred_knn = knn.predict(X_test_stem)\n",
    "y_pred_classifier = classifier.predict(X_test_stem)\n",
    "y_pred_naive = naive.predict(X_test_stem)\n",
    "y_pred_dtc = dtc.predict(X_test_stem)\n",
    "y_pred_rfc = rfc.predict(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : \n",
      " [[241 105]\n",
      " [ 85 284]]\n",
      "K-NN : \n",
      " [[231 115]\n",
      " [197 172]]\n",
      "SVM :  [[246 100]\n",
      " [ 97 272]]\n",
      "Naive Bayes : \n",
      " [[123 223]\n",
      " [ 97 272]]\n",
      "Decision Tree Classifier : \n",
      " [[185 161]\n",
      " [130 239]]\n",
      "Random Forest Classifier : \n",
      " [[195 151]\n",
      " [ 60 309]]\n",
      "Accuracy of Logistic Regression Classifier is : 0.7342657342657343 \n",
      "\n",
      "Accuracy of K_NN Classifier is : 0.5636363636363636 \n",
      "\n",
      "Accuracy of SVM Classifier is : 0.7244755244755244 \n",
      "\n",
      "Accuracy of Naive Bayes Classifier is : 0.5524475524475524 \n",
      "\n",
      "Accuracy of Decision Tree Classifier is : 0.593006993006993 \n",
      "\n",
      "Accuracy of Random Forest Classifier is : 0.7048951048951049 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm_lr = confusion_matrix(y_test,y_pred_lr)\n",
    "print('Logistic Regression : \\n',cm_lr)\n",
    "cm_knn = confusion_matrix(y_test,y_pred_knn)\n",
    "print('K-NN : \\n',cm_knn)\n",
    "cm_classifier = confusion_matrix(y_test,y_pred_classifier)\n",
    "print('SVM : ',cm_classifier)\n",
    "cm_naive = confusion_matrix(y_test,y_pred_naive)\n",
    "print('Naive Bayes : \\n',cm_naive)\n",
    "cm_dtc = confusion_matrix(y_test,y_pred_dtc)\n",
    "print('Decision Tree Classifier : \\n',cm_dtc)\n",
    "cm_rfc = confusion_matrix(y_test,y_pred_rfc)\n",
    "print('Random Forest Classifier : \\n', cm_rfc)\n",
    "print('Accuracy of Logistic Regression Classifier is :', accuracy_score(y_test,y_pred_lr),'\\n')\n",
    "print('Accuracy of K_NN Classifier is :', accuracy_score(y_test,y_pred_knn),'\\n')\n",
    "print('Accuracy of SVM Classifier is :' ,accuracy_score(y_test,y_pred_classifier),'\\n')\n",
    "print('Accuracy of Naive Bayes Classifier is :', accuracy_score(y_test,y_pred_naive),'\\n')\n",
    "print('Accuracy of Decision Tree Classifier is :',accuracy_score(y_test,y_pred_dtc),'\\n')\n",
    "print('Accuracy of Random Forest Classifier is :' ,accuracy_score(y_test,y_pred_rfc),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
